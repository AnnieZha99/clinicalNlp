{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64552bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\annie\\anaconda3\\lib\\site-packages (from biopython) (1.26.4)\n",
      "Downloading biopython-1.85-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 32.8 MB/s eta 0:00:00\n",
      "Installing collected packages: biopython\n",
      "Successfully installed biopython-1.85\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install biopython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ecf9b",
   "metadata": {},
   "source": [
    "# Project Idea: Relation Extraction on PubMed Articles About Alzheimer's Disease\n",
    "\n",
    "## üéØ Objective:\n",
    "Extract and categorize relationships from PubMed abstracts or full-texts related to Alzheimer's disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6a6a0",
   "metadata": {},
   "source": [
    "Fetch PubMed Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cde8810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 articles for query: 'Alzheimer's disease'\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "from time import sleep\n",
    "\n",
    "# Set your email ‚Äî this is required by NCBI\n",
    "Entrez.email = \"your_email@example.com\"\n",
    "\n",
    "def fetch_pubmed_abstracts(query, max_results=100):\n",
    "    # Search PubMed\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    id_list = record[\"IdList\"]\n",
    "    print(f\"Found {len(id_list)} articles for query: '{query}'\")\n",
    "\n",
    "    abstracts = []\n",
    "    for pmid in id_list:\n",
    "        try:\n",
    "            # Fetch article metadata\n",
    "            fetch_handle = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"abstract\", retmode=\"text\")\n",
    "            abstract_text = fetch_handle.read()\n",
    "            abstracts.append((pmid, abstract_text))\n",
    "            fetch_handle.close()\n",
    "            sleep(0.5)  # Be kind to NCBI servers\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching PMID {pmid}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return abstracts\n",
    "\n",
    "# Run the script\n",
    "query = \"Alzheimer's disease\"\n",
    "abstracts = fetch_pubmed_abstracts(query, max_results=100)\n",
    "\n",
    "# Save to file\n",
    "with open(\"alzheimers_pubmed_abstracts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for pmid, abstract in abstracts:\n",
    "        f.write(f\"PMID: {pmid}\\n\")\n",
    "        f.write(abstract + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63687f4",
   "metadata": {},
   "source": [
    "### Step 1: NER (Entity Detection)\n",
    "Use SciSpacy or BioBERT to find:\n",
    "\n",
    "- DISEASE (e.g., Alzheimer‚Äôs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d3da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def split_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e995dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 2534\n"
     ]
    }
   ],
   "source": [
    "with open(\"alzheimers_pubmed_abstracts.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    abstracts = f.read().split(\"PMID:\")\n",
    "\n",
    "all_sentences = []\n",
    "for entry in abstracts:\n",
    "    if entry.strip():\n",
    "        text = entry.strip().split(\"\\n\", 1)[-1]\n",
    "        sentences = split_sentences(text)\n",
    "        all_sentences.extend(sentences)\n",
    "\n",
    "print(\"Total sentences:\", len(all_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66a3c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Annie\\anaconda3\\Lib\\site-packages\\spacy\\language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "\n",
    "def get_disease_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents if ent.label_ == \"DISEASE\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93d4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_disease_name(name):\n",
    "    name = name.lower()\n",
    "    if \"alzheimer\" in name:\n",
    "        return \"Alzheimer's disease\"\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f341e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_alz_related_pairs(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    diseases = [normalize_disease_name(ent.text) for ent in doc.ents if ent.label_ == \"DISEASE\"]\n",
    "    \n",
    "    # Get unique lowercase disease list (for robust matching)\n",
    "    unique_diseases = list(set(diseases))\n",
    "    alz_diseases = [d for d in unique_diseases if \"alzheimer\" in d.lower()]\n",
    "    \n",
    "    pairs = []\n",
    "    for ad in alz_diseases:\n",
    "        for d in unique_diseases:\n",
    "            if d.lower() != ad.lower():\n",
    "                pairs.append((ad, d))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09a180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Annie\\anaconda3\\Lib\\site-packages\\scispacy\\abbreviation.py:248: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  global_matches = self.global_matcher(doc)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "output_rows = []\n",
    "\n",
    "for sent in all_sentences:\n",
    "    pairs = extract_alz_related_pairs(sent)\n",
    "    for p1, p2 in pairs:\n",
    "        output_rows.append({\n",
    "            \"sentence\": sent,\n",
    "            \"entity_1\": p1,\n",
    "            \"entity_2\": p2,\n",
    "            \"relation_label\": \"\"  # ‚Üê leave empty for annotation\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417984b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication: 202 pairs\n"
     ]
    }
   ],
   "source": [
    "unique_rows = set()\n",
    "deduplicated = []\n",
    "\n",
    "for row in output_rows:\n",
    "    key = (row[\"sentence\"], row[\"entity_1\"].lower(), row[\"entity_2\"].lower())\n",
    "    if key not in unique_rows:\n",
    "        unique_rows.add(key)\n",
    "        deduplicated.append(row)\n",
    "\n",
    "print(f\"After deduplication: {len(deduplicated)} pairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742b782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 202 pairs to 'alz_disease_pairs_for_annotation.csv'\n"
     ]
    }
   ],
   "source": [
    "with open(\"alz_disease_pairs_for_annotation.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"sentence\", \"entity_1\", \"entity_2\", \"relation_label\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(deduplicated)\n",
    "\n",
    "print(f\"Saved {len(deduplicated)} pairs to 'alz_disease_pairs_for_annotation.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
